{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from data import InMemoryExerciseData\n",
    "from lstm import LSTM\n",
    "\n",
    "def initialize_sess():\n",
    "    global sess\n",
    "    ruv = set(sess.run(tf.report_uninitialized_variables()))\n",
    "    uv = [v for v in tf.global_variables() if v.name.split(':')[0].encode('ascii') in ruv]\n",
    "    tf.variables_initializer(uv).run()\n",
    "    \n",
    "def reset_sess():\n",
    "    global sess\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "    sess = tf.InteractiveSession()    \n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "min_seq_length = 5\n",
    "max_seq_length = 3000\n",
    "min_correct = 2\n",
    "min_responses_for_skill = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bridge_to_algebra_2006_2007_train.txt', sep='\\t', lineterminator='\\r',\n",
    "                 usecols=['Anon Student Id', 'KC(SubSkills)', 'Correct First Attempt', 'Corrects',\n",
    "                          'Incorrects', 'Step Start Time','Problem Name', 'Step Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skillRules = [skill for skill in df['KC(SubSkills)'].unique() if str(skill)[0:10] == '[SkillRule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATETIME IS STORED IN NANOSECONDS\n",
    "df['date'] = pd.to_datetime(df['Step Start Time']).astype(np.int64) // 10 ** 9\n",
    "df.drop(['Step Start Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['_count'] = 1\n",
    "grouped_df = df.groupby('KC(SubSkills)').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num KCs: 12\n"
     ]
    }
   ],
   "source": [
    "for idx, x in enumerate(grouped_df['_count'].sort_values(ascending=False)):\n",
    "    if x < min_responses_for_skill:\n",
    "        break\n",
    "chosen_skill_names_plus = grouped_df['_count'].sort_values(ascending=False)[0:idx].index\n",
    "chosen_skill_names = [skill for skill in chosen_skill_names_plus if skill not in [\"Enter answer digit -- DON'T TRACK ME\",\n",
    "                                                                                  'Enter quantity from diagram by reading',\n",
    "                                                                                  'Entering a given']]\n",
    "# chosen_skill_names = skillRules[0:12]\n",
    "print(\"Num KCs: %d\" % (len(chosen_skill_names)))\n",
    "df = df[df['KC(SubSkills)'].isin(chosen_skill_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Students: 1023\n"
     ]
    }
   ],
   "source": [
    "grouped_df = df.groupby('Anon Student Id').sum()\n",
    "filtered_uids = grouped_df[(grouped_df['_count'] >= min_seq_length) &\n",
    "                           (grouped_df['_count'] <= max_seq_length) &\n",
    "                           (grouped_df['Corrects'] >= min_correct)].reset_index()['Anon Student Id']\n",
    "print(\"Num Students: %d\" % (len(filtered_uids)))\n",
    "df = df[df['Anon Student Id'].isin(filtered_uids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_day(df, new_day_threshold=5, verbose=True):\n",
    "    \"\"\"\n",
    "    Processes data to include correctness of the previous question and whether it has been a day since the\n",
    "    the last response to any skill.\n",
    "    Ex. For exercises A and B:\n",
    "        [0, 0, 1, 1, 0, 1]\n",
    "        Means that the current response is for exercise B, is incorrect and it has been a day since the \n",
    "        previous response to an exercise.\n",
    "    \"\"\"\n",
    "    num_students = df['Anon Student Id'].nunique()\n",
    "    num_skills = df['KC(SubSkills)'].nunique()\n",
    "    new_day_threshold = 5 * 60 * 60 # Convert to seconds\n",
    "\n",
    "    corrects = np.zeros((num_students, max_seq_length, num_skills))\n",
    "    mask = np.zeros((num_students, max_seq_length, num_skills))\n",
    "    sequences = np.zeros((num_students, max_seq_length, 3 * num_skills))\n",
    "\n",
    "    exercise_index_map = {}\n",
    "    for idx, exercise in enumerate(df['KC(SubSkills)'].unique()):\n",
    "        exercise_index_map[exercise] = idx * 3\n",
    "\n",
    "    for row_idx, uid in enumerate(df['Anon Student Id'].unique()):\n",
    "        uid_df = df[df['Anon Student Id'] == uid]\n",
    "        col_idx = 0\n",
    "        prev_date = 0.0\n",
    "\n",
    "        for _, event in uid_df.iterrows():\n",
    "            idx = exercise_index_map[event['KC(SubSkills)']]\n",
    "            sequences[row_idx, col_idx, idx] = 1\n",
    "            sequences[row_idx, col_idx, idx + 1] = event['Correct First Attempt']\n",
    "            if event['date'] - prev_date > new_day_threshold:\n",
    "                sequences[row_idx, col_idx] += np.array([0, 0, 1] * num_skills)\n",
    "                        \n",
    "            prev_date = event['date']\n",
    "            corrects[row_idx, col_idx, idx // 3] = event['Correct First Attempt']\n",
    "            mask[row_idx, col_idx, idx // 3] = 1\n",
    "            col_idx += 1\n",
    "\n",
    "        if verbose and row_idx % 100 == 0:\n",
    "            print(\"Processed %d\" % row_idx)\n",
    "\n",
    "    return InMemoryExerciseData(sequences, mask, corrects)\n",
    "\n",
    "def correctness_only(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Processes data to only include correctness of the previous question as input.\n",
    "    Ex. For exercises A and B:\n",
    "        [0, 0, 1, 0]\n",
    "        Means that the current response is for exercise B and is incorrect.\n",
    "    \"\"\"\n",
    "    num_students = df['Anon Student Id'].nunique()\n",
    "    num_skills = df['KC(SubSkills)'].nunique()\n",
    "\n",
    "    corrects = np.zeros((num_students, max_seq_length, num_skills))\n",
    "    mask = np.zeros((num_students, max_seq_length, num_skills))\n",
    "    sequences = np.zeros((num_students, max_seq_length, 2 * num_skills))\n",
    "\n",
    "    exercise_index_map = {}\n",
    "    for idx, exercise in enumerate(df['KC(SubSkills)'].unique()):\n",
    "        exercise_index_map[exercise] = idx * 2\n",
    "\n",
    "    for row_idx, uid in enumerate(df['Anon Student Id'].unique()):\n",
    "        uid_df = df[df['Anon Student Id'] == uid]\n",
    "        col_idx = 0\n",
    "\n",
    "        for _, event in uid_df.iterrows():\n",
    "            idx = exercise_index_map[event['KC(SubSkills)']]\n",
    "            sequences[row_idx, col_idx, idx] = 1\n",
    "            sequences[row_idx, col_idx, idx + 1] = event['Correct First Attempt']\n",
    "\n",
    "            corrects[row_idx, col_idx, idx // 2] = event['Correct First Attempt']\n",
    "            mask[row_idx, col_idx, idx // 2] = 1\n",
    "            col_idx += 1\n",
    "\n",
    "        if verbose and row_idx % 100 == 0:\n",
    "            print(\"Processed %d\" % row_idx)\n",
    "\n",
    "    return InMemoryExerciseData(sequences, mask, corrects)\n",
    "\n",
    "def new_day_by_exercise(df, new_day_threshold=5, verbose=True):\n",
    "    \"\"\"\n",
    "    Processes data to include correctness of the previous question and whether it has been a day since the\n",
    "    the last response to this skill.\n",
    "    Ex. For exercises A and B:\n",
    "        [0, 0, 1, 1, 0, 0]\n",
    "        Means that the current response is for exercise B, is incorrect and it is not a new day for B. It\n",
    "        is a new day for A.\n",
    "    \"\"\"\n",
    "    num_students = df['Anon Student Id'].nunique()\n",
    "    num_skills = df['KC(SubSkills)'].nunique()\n",
    "    new_day_threshold = 5 * 60 * 60 # Convert to seconds\n",
    "\n",
    "    corrects = np.zeros((num_students, max_seq_length, num_skills))\n",
    "    mask = np.zeros((num_students, max_seq_length, num_skills))\n",
    "    sequences = np.zeros((num_students, max_seq_length, 3 * num_skills))\n",
    "\n",
    "    exercise_index_map = {}\n",
    "    for idx, exercise in enumerate(df['KC(SubSkills)'].unique()):\n",
    "        exercise_index_map[exercise] = idx * 3\n",
    "\n",
    "    for row_idx, uid in enumerate(df['Anon Student Id'].unique()):\n",
    "        uid_df = df[df['Anon Student Id'] == uid]\n",
    "        col_idx = 0\n",
    "        prev_dates = np.zeros((3 * num_skills))\n",
    "\n",
    "        for _, event in uid_df.iterrows():\n",
    "            idx = exercise_index_map[event['KC(SubSkills)']]\n",
    "            sequences[row_idx, col_idx, idx] = 1\n",
    "            sequences[row_idx, col_idx, idx + 1] = event['Correct First Attempt']\n",
    "            sequences[row_idx, col_idx] += ((np.ones((3 * num_skills)) * event['date'] - prev_dates) * (prev_dates != 0)) > new_day_threshold\n",
    "                        \n",
    "            prev_dates[idx + 2] = event['date']\n",
    "            corrects[row_idx, col_idx, idx // 3] = event['Correct First Attempt']\n",
    "            mask[row_idx, col_idx, idx // 3] = 1\n",
    "            col_idx += 1\n",
    "\n",
    "        if verbose and row_idx % 100 == 0:\n",
    "            print(\"Processed %d\" % row_idx)\n",
    "\n",
    "    return InMemoryExerciseData(sequences, mask, corrects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0\n",
      "Processed 100\n",
      "Processed 200\n",
      "Processed 300\n",
      "Processed 400\n",
      "Processed 500\n",
      "Processed 600\n",
      "Processed 700\n",
      "Processed 800\n",
      "Processed 900\n",
      "Processed 1000\n",
      "Processed 0\n",
      "Processed 100\n",
      "Processed 200\n",
      "Processed 300\n",
      "Processed 400\n",
      "Processed 500\n",
      "Processed 600\n",
      "Processed 700\n",
      "Processed 800\n",
      "Processed 900\n",
      "Processed 1000\n",
      "Processed 0\n",
      "Processed 100\n",
      "Processed 200\n",
      "Processed 300\n",
      "Processed 400\n",
      "Processed 500\n",
      "Processed 600\n",
      "Processed 700\n",
      "Processed 800\n",
      "Processed 900\n",
      "Processed 1000\n"
     ]
    }
   ],
   "source": [
    "correctness_only_data = correctness_only(df)\n",
    "new_day_data = new_day(df)\n",
    "new_day_by_exercise_data = new_day_by_exercise(df)\n",
    "\n",
    "datasets = [correctness_only_data, new_day_data, new_day_by_exercise_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--UNWEIGHTED--\n",
      "Correctness Only\n",
      "Fold 1\n",
      "Accuracy: 0.885806, Baseline: 0.885806, AUC: 0.612333, MAE: 0.196806, CE: 2.632014\n",
      "Fold 2\n",
      "Accuracy: 0.901120, Baseline: 0.901120, AUC: 0.590038, MAE: 0.195088, CE: 3.013435\n",
      "Fold 3\n",
      "Accuracy: 0.888383, Baseline: 0.888383, AUC: 0.597144, MAE: 0.206588, CE: 2.404195\n",
      "Fold 4\n",
      "Accuracy: 0.885806, Baseline: 0.885806, AUC: 0.606203, MAE: 0.205402, CE: 1.603371\n",
      "Fold 5\n",
      "Accuracy: 0.872028, Baseline: 0.872028, AUC: 0.637995, MAE: 0.220470, CE: 2.091223\n",
      "Fold 6\n",
      "Accuracy: 0.895073, Baseline: 0.894812, AUC: 0.663101, MAE: 0.200829, CE: 1.945569\n",
      "Fold 7\n",
      "Accuracy: 0.876557, Baseline: 0.876557, AUC: 0.576807, MAE: 0.226991, CE: 3.242107\n",
      "Fold 8\n",
      "Accuracy: 0.852551, Baseline: 0.852551, AUC: 0.634040, MAE: 0.229741, CE: 3.721224\n",
      "Fold 9\n",
      "Accuracy: 0.891087, Baseline: 0.891087, AUC: 0.636713, MAE: 0.199534, CE: 2.573182\n",
      "Fold 10\n",
      "Accuracy: 0.916132, Baseline: 0.916132, AUC: 0.626838, MAE: 0.170637, CE: 2.614731\n",
      "Fold 11\n",
      "Accuracy: 0.858977, Baseline: 0.859735, AUC: 0.659039, MAE: 0.218475, CE: 2.848933\n",
      "Fold 12\n",
      "Accuracy: 0.870290, Baseline: 0.870290, AUC: 0.657382, MAE: 0.209169, CE: 3.310268\n",
      "Fold 13\n",
      "Accuracy: 0.862815, Baseline: 0.862815, AUC: 0.714854, MAE: 0.205812, CE: 2.694617\n",
      "Fold 14\n",
      "Accuracy: 0.872031, Baseline: 0.872031, AUC: 0.666464, MAE: 0.202306, CE: 1.927835\n",
      "Fold 15\n",
      "Accuracy: 0.887780, Baseline: 0.887780, AUC: 0.663938, MAE: 0.185631, CE: 2.735016\n",
      "Average Accuracy: 0.88109583, Average AUC 0.63619265, Average MAE 0.20489854, Average CE: 0.00001367\n",
      "New Day Aggregate\n",
      "Fold 1\n",
      "Accuracy: 0.885806, Baseline: 0.885806, AUC: 0.613926, MAE: 0.195968, CE: 2.631461\n",
      "Fold 2\n",
      "Accuracy: 0.901120, Baseline: 0.901120, AUC: 0.596916, MAE: 0.186942, CE: 3.009895\n",
      "Fold 3\n",
      "Accuracy: 0.888383, Baseline: 0.888383, AUC: 0.597098, MAE: 0.200365, CE: 2.401731\n",
      "Fold 4\n",
      "Accuracy: 0.885806, Baseline: 0.885806, AUC: 0.608730, MAE: 0.197420, CE: 1.607426\n",
      "Fold 5\n",
      "Accuracy: 0.872028, Baseline: 0.872028, AUC: 0.633083, MAE: 0.209269, CE: 2.093621\n",
      "Fold 6\n",
      "Accuracy: 0.894812, Baseline: 0.894812, AUC: 0.642455, MAE: 0.193143, CE: 1.947408\n",
      "Fold 7\n",
      "Accuracy: 0.876557, Baseline: 0.876557, AUC: 0.593187, MAE: 0.213508, CE: 3.238057\n",
      "Fold 8\n",
      "Accuracy: 0.852551, Baseline: 0.852551, AUC: 0.647179, MAE: 0.232028, CE: 3.717684\n",
      "Fold 9\n",
      "Accuracy: 0.891087, Baseline: 0.891087, AUC: 0.594931, MAE: 0.192916, CE: 2.576814\n",
      "Fold 10\n",
      "Accuracy: 0.916132, Baseline: 0.916132, AUC: 0.618479, MAE: 0.172963, CE: 2.616342\n",
      "Fold 11\n",
      "Accuracy: 0.859735, Baseline: 0.859735, AUC: 0.671746, MAE: 0.215686, CE: 2.846082\n",
      "Fold 12\n",
      "Accuracy: 0.870290, Baseline: 0.870290, AUC: 0.684836, MAE: 0.205820, CE: 3.306799\n",
      "Fold 13\n",
      "Accuracy: 0.862769, Baseline: 0.862815, AUC: 0.732962, MAE: 0.202604, CE: 2.683390\n",
      "Fold 14\n",
      "Accuracy: 0.872031, Baseline: 0.872031, AUC: 0.700197, MAE: 0.196993, CE: 1.922614\n",
      "Fold 15\n",
      "Accuracy: 0.887780, Baseline: 0.887780, AUC: 0.639578, MAE: 0.192330, CE: 2.738246\n",
      "Average Accuracy: 0.88112595, Average AUC 0.63835352, Average MAE 0.20053035, Average CE: 0.00001366\n",
      "New Day by Exercise\n",
      "Fold 1\n",
      "Accuracy: 0.885806, Baseline: 0.885806, AUC: 0.625135, MAE: 0.196628, CE: 2.629270\n",
      "Fold 2\n",
      "Accuracy: 0.901120, Baseline: 0.901120, AUC: 0.606047, MAE: 0.187707, CE: 3.009451\n",
      "Fold 3\n",
      "Accuracy: 0.888383, Baseline: 0.888383, AUC: 0.612469, MAE: 0.207039, CE: 2.402513\n",
      "Fold 4\n",
      "Accuracy: 0.885806, Baseline: 0.885806, AUC: 0.616827, MAE: 0.204267, CE: 1.602446\n",
      "Fold 5\n",
      "Accuracy: 0.872028, Baseline: 0.872028, AUC: 0.658575, MAE: 0.219895, CE: 2.090493\n",
      "Fold 6\n",
      "Accuracy: 0.894812, Baseline: 0.894812, AUC: 0.631055, MAE: 0.195820, CE: 1.947996\n",
      "Fold 7\n",
      "Accuracy: 0.876557, Baseline: 0.876557, AUC: 0.614476, MAE: 0.217676, CE: 3.238603\n",
      "Fold 8\n",
      "Accuracy: 0.852551, Baseline: 0.852551, AUC: 0.661231, MAE: 0.235411, CE: 3.714841\n",
      "Fold 9\n",
      "Accuracy: 0.891087, Baseline: 0.891087, AUC: 0.603284, MAE: 0.187327, CE: 2.575703\n",
      "Fold 10\n",
      "Accuracy: 0.916132, Baseline: 0.916132, AUC: 0.645188, MAE: 0.166750, CE: 2.611277\n",
      "Fold 11\n",
      "Accuracy: 0.859735, Baseline: 0.859735, AUC: 0.684229, MAE: 0.213529, CE: 2.847158\n",
      "Fold 12\n",
      "Accuracy: 0.870290, Baseline: 0.870290, AUC: 0.703342, MAE: 0.198752, CE: 3.306086\n",
      "Fold 13\n",
      "Accuracy: 0.862815, Baseline: 0.862815, AUC: 0.715252, MAE: 0.208724, CE: 2.694471\n",
      "Fold 14\n",
      "Accuracy: 0.872031, Baseline: 0.872031, AUC: 0.682771, MAE: 0.202098, CE: 1.921811\n",
      "Fold 15\n",
      "Accuracy: 0.887780, Baseline: 0.887780, AUC: 0.665859, MAE: 0.186254, CE: 2.736312\n",
      "Average Accuracy: 0.88112897, Average AUC 0.64838259, Average MAE 0.20185841, Average CE: 0.00001366\n"
     ]
    }
   ],
   "source": [
    "print(\"--UNWEIGHTED--\")\n",
    "unweighted_scores = {}\n",
    "for data, name in zip(datasets, [\"Correctness Only\", \"New Day Aggregate\", \"New Day by Exercise\"]):\n",
    "    print(name)\n",
    "    reset_sess()\n",
    "    lstm = LSTM(hidden_dim=200,\n",
    "                output_dim=data.targets.shape[2],\n",
    "                input_dim=data.inputs.shape[2],\n",
    "                learning_rate=1e-2,\n",
    "                batch_size=64,\n",
    "                num_layers=1)\n",
    "\n",
    "    lstm.build_model(tf.sigmoid)\n",
    "\n",
    "    k = 15\n",
    "    unweighted_scores[name] = {\n",
    "        \"accuracy\": [],\n",
    "        \"baseline\": [], # should be identical for all groups\n",
    "        \"AUC\": [],\n",
    "        \"MAE\": [],\n",
    "        \"CE\": []\n",
    "    }\n",
    "    for fold in data.k_fold(k):\n",
    "        print(\"Fold %d\" % fold)\n",
    "        tf.global_variables_initializer().run()\n",
    "        lstm.train(sess, data, epochs=3)\n",
    "        acc, baseline, auc, mae, ce = lstm.test(sess, data)\n",
    "        unweighted_scores[name][\"accuracy\"].append(acc)\n",
    "        unweighted_scores[name][\"baseline\"].append(baseline)\n",
    "        unweighted_scores[name][\"AUC\"].append(auc)\n",
    "        unweighted_scores[name][\"MAE\"].append(mae)\n",
    "        unweighted_scores[name][\"CE\"].append(ce)\n",
    "        \n",
    "    \n",
    "    print(\"Average Accuracy: %.8f, Average AUC %.8f, Average MAE %.8f, Average CE: %.8f\" % (np.mean(unweighted_scores[name][\"accuracy\"]),\n",
    "                                                                                            np.mean(unweighted_scores[name][\"AUC\"]),\n",
    "                                                                                            np.mean(unweighted_scores[name][\"MAE\"]),\n",
    "                                                                                            np.mean(unweighted_scores[name][\"CE\"])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--WEIGHTED 1.5x--\")\n",
    "for data, name in zip(datasets, [\"Correctness Only\", \"New Day Aggregate\", \"New Day by Exercise\"]):\n",
    "    print(name)\n",
    "    data.target_masks = data.target_masks * 3/2 - data.targets * (3/2 - 1)\n",
    "    reset_sess()\n",
    "    lstm = LSTM(hidden_dim=200,\n",
    "                output_dim=data.targets.shape[2],\n",
    "                input_dim=data.inputs.shape[2],\n",
    "                learning_rate=1e-2,\n",
    "                batch_size=64,\n",
    "                num_layers=1)\n",
    "\n",
    "    lstm.build_model(tf.sigmoid)\n",
    "\n",
    "    k = 15\n",
    "    avg_acc = 0.0\n",
    "    avg_auc = 0.0\n",
    "    avg_mae = 0.0\n",
    "    for fold in data.k_fold(k):\n",
    "        print(\"Fold %d\" % fold)\n",
    "        tf.global_variables_initializer().run()\n",
    "        lstm.train(sess, data, epochs=3)\n",
    "        acc, baseline, auc, mae = lstm.test(sess, data)\n",
    "        avg_acc += acc / k\n",
    "        avg_auc += auc / k\n",
    "        avg_mae += mae / k\n",
    "    \n",
    "    print(\"Average Accuracy: %.8f, Average AUC %.8f, Average Mean Absolute Error %.8f\" % (avg_acc, avg_auc, avg_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired T-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unweighted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_correctness_only = unweighted_scores[\"Correctness Only\"]\n",
    "unweighted_new_day_aggregate = unweighted_scores[\"New Day Aggregate\"]\n",
    "unweighted_new_day_by_exercise = unweighted_scores[\"New Day by Exercise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctness vs. New Day Aggregate\n",
      "  Accuracy: t-statistic -0.549320, p-value 0.591441\n",
      "  AUC: t-statistic -0.415951, p-value 0.683752\n",
      "  MAE: t-statistic 3.139861, p-value 0.007236\n"
     ]
    }
   ],
   "source": [
    "print(\"Correctness vs. New Day Aggregate\")\n",
    "acc_result = stats.ttest_rel(unweighted_correctness_only[\"accuracy\"], unweighted_new_day_aggregate[\"accuracy\"])\n",
    "auc_result = stats.ttest_rel(unweighted_correctness_only[\"AUC\"], unweighted_new_day_aggregate[\"AUC\"])\n",
    "mae_result = stats.ttest_rel(unweighted_correctness_only[\"MAE\"], unweighted_new_day_aggregate[\"MAE\"])\n",
    "print(\"  Accuracy: t-statistic %.6f, p-value %.6f\" % acc_result)\n",
    "print(\"  AUC: t-statistic %.6f, p-value %.6f\" % auc_result)\n",
    "print(\"  MAE: t-statistic %.6f, p-value %.6f\" % mae_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctness vs. New Day by Exercise\n",
      "  Accuracy: t-statistic -0.606701, p-value 0.553762\n",
      "  AUC: t-statistic -2.171335, p-value 0.047585\n",
      "  MAE: t-statistic 2.297483, p-value 0.037529\n"
     ]
    }
   ],
   "source": [
    "print(\"Correctness vs. New Day by Exercise\")\n",
    "acc_result = stats.ttest_rel(unweighted_correctness_only[\"accuracy\"], unweighted_new_day_by_exercise[\"accuracy\"])\n",
    "auc_result = stats.ttest_rel(unweighted_correctness_only[\"AUC\"], unweighted_new_day_by_exercise[\"AUC\"])\n",
    "mae_result = stats.ttest_rel(unweighted_correctness_only[\"MAE\"], unweighted_new_day_by_exercise[\"MAE\"])\n",
    "print(\"  Accuracy: t-statistic %.6f, p-value %.6f\" % acc_result)\n",
    "print(\"  AUC: t-statistic %.6f, p-value %.6f\" % auc_result)\n",
    "print(\"  MAE: t-statistic %.6f, p-value %.6f\" % mae_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_correctness_only = {\n",
    "    \"accuracy\": [0.88568, 0.90380, 0.88392, 0.89487, 0.87396, 0.89272, 0.87284, 0.86231, 0.88940,\n",
    "                 0.91799, 0.85268, 0.87077, 0.85659, 0.87699, 0.88499],\n",
    "    \"baseline\": [0.88568, 0.90380, 0.88392, 0.89487, 0.87396, 0.89294, 0.87284, 0.86231, 0.88935,\n",
    "                 0.91847, 0.85268, 0.87077, 0.85659, 0.88001, 0.88499], # should be identical for all groups\n",
    "    \"AUC\": [0.50000, 0.49999, 0.50870, 0.50000, 0.50000, 0.53163, 0.49955, 0.49996, 0.50317, 0.49008,\n",
    "            0.50015, 0.50038, 0.49990, 0.46609, 0.50007],\n",
    "    \"MAE\": [0.20711, 0.19805, 0.20756, 0.21623, 0.25571, 0.21628, 0.27396, 0.27459, 0.23941, 0.22065,\n",
    "            0.23682, 0.23068, 0.23206, 0.22245, 0.21569]\n",
    "}\n",
    "\n",
    "weighted_new_day_aggregate = {\n",
    "    \"accuracy\": [0.88568, 0.90380, 0.88392, 0.89487, 0.87392, 0.89294, 0.87284, 0.86228, 0.88935,\n",
    "                 0.91842, 0.85268, 0.87077, 0.85659, 0.88001, 0.88660],\n",
    "    \"baseline\": [0.88568, 0.90380, 0.88392, 0.89487, 0.87396, 0.89294, 0.87284, 0.86231, 0.88935,\n",
    "                 0.91847, 0.85268, 0.87077, 0.85659, 0.88001, 0.88499], # should be identical for all groups\n",
    "    \"AUC\": [0.50000, 0.50000, 0.49944, 0.50000, 0.50066, 0.49996, 0.50000, 0.50317, 0.50000, 0.51416,\n",
    "            0.50042, 0.50014, 0.50000, 0.50001, 0.54129],\n",
    "    \"MAE\": [0.20800, 0.21037, 0.21817, 0.19948, 0.25157, 0.23541, 0.27970, 0.27187, 0.21337, 0.21905,\n",
    "            0.24697, 0.20455, 0.24985, 0.22025, 0.21653]\n",
    "}\n",
    "    \n",
    "weighted_new_day_by_exercise = {\n",
    "    \"accuracy\": [0.88568, 0.90380, 0.88392, 0.89478, 0.87396, 0.89294, 0.87284, 0.86231, 0.88935,\n",
    "                 0.91847, 0.85190, 0.87077, 0.85589, 0.87961, 0.88499],\n",
    "    \"baseline\": [0.88568, 0.90380, 0.88392, 0.89487, 0.87396, 0.89294, 0.87284, 0.86231, 0.88935,\n",
    "                 0.91847, 0.85268, 0.87077, 0.85659, 0.88001, 0.88499], # should be identical for all groups\n",
    "    \"AUC\": [0.49999, 0.49999, 0.50000, 0.49775, 0.49838, 0.50000, 0.49974, 0.50011, 0.49999, 0.50000,\n",
    "            0.45629, 0.50011, 0.49970, 0.50098, 0.50014],\n",
    "    \"MAE\": [0.21873, 0.20113, 0.23784, 0.23223, 0.25360, 0.24602, 0.28396, 0.27601, 0.24146, 0.24013,\n",
    "            0.24360, 0.23676, 0.21917, 0.22045, 0.23518]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correctness vs. New Day Aggregate\")\n",
    "acc_result = stats.ttest_rel(weighted_correctness_only[\"accuracy\"], weighted_new_day_aggregate[\"accuracy\"])\n",
    "auc_result = stats.ttest_rel(weighted_correctness_only[\"AUC\"], weighted_new_day_aggregate[\"AUC\"])\n",
    "mae_result = stats.ttest_rel(weighted_correctness_only[\"MAE\"], weighted_new_day_aggregate[\"MAE\"])\n",
    "print(\"  Accuracy: t-statistic %.6f, p-value %.6f\" % acc_result)\n",
    "print(\"  AUC: t-statistic %.6f, p-value %.6f\" % auc_result)\n",
    "print(\"  MAE: t-statistic %.6f, p-value %.6f\" % mae_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correctness vs. New Day by Exercise\")\n",
    "acc_result = stats.ttest_rel(weighted_correctness_only[\"accuracy\"], weighted_new_day_by_exercise[\"accuracy\"])\n",
    "auc_result = stats.ttest_rel(weighted_correctness_only[\"AUC\"], weighted_new_day_by_exercise[\"AUC\"])\n",
    "mae_result = stats.ttest_rel(weighted_correctness_only[\"MAE\"], weighted_new_day_by_exercise[\"MAE\"])\n",
    "print(\"  Accuracy: t-statistic %.6f, p-value %.6f\" % acc_result)\n",
    "print(\"  AUC: t-statistic %.6f, p-value %.6f\" % auc_result)\n",
    "print(\"  MAE: t-statistic %.6f, p-value %.6f\" % mae_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['List consecutive multiples of a number',\n",
       "       'Identify number as common multiple',\n",
       "       'Identify number as common factor', 'List factor of large number',\n",
       "       'Identify Fraction using fraction shape',\n",
       "       'Identify number of items', 'Identify number of recipients',\n",
       "       'Identify proper fraction from option 1',\n",
       "       'Identify proper fraction from option 2',\n",
       "       'Compare Options - operation',\n",
       "       'Label equivalent fraction in equivalence statement',\n",
       "       'Rewrite fraction with common denominator'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['KC(SubSkills)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
